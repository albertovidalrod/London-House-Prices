{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geocoder\n",
    "import re\n",
    "\n",
    "import dask\n",
    "import dask.multiprocessing\n",
    "import dask.dataframe as dd\n",
    "from dask import delayed\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.utils import (\n",
    "    extract_area_from_floorplan,\n",
    "    find_postcode,\n",
    "    extract_area_from_dataframe,\n",
    "    extract_other_data_from_floorplan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_pictures = os.listdir(\"media/house_pictures\")\n",
    "house_pictures = [file for file in house_pictures if file != \".DS_Store\"]\n",
    "for folder in house_pictures:\n",
    "    files = os.listdir(f\"media/house_pictures/{folder}\")\n",
    "    if not files:\n",
    "        print(f\"{folder} is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = pd.read_parquet(\"data/August 2023/house_data_no_garden_NW34TG.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(test_values[\"price_change_date\"][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 19)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_items = [np.size(item)==0 for item in test_values[\"price_change_date\"]]\n",
    "sum(empty_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# garden_mentions_garden = garden_data[\"key_features\"].apply(\n",
    "#     lambda x: any(\"garden\" in item.lower() for item in x)\n",
    "# )\n",
    "# communal_garden_mentions_no_garden = garden_no_garden_data[\"key_features\"].apply(\n",
    "#     lambda x: any(\"communal garden\" in item.lower() for item in x)\n",
    "# )\n",
    "# garden_mentions_no_garden = garden_no_garden_data[\"key_features\"].apply(\n",
    "#     lambda x: any(\"garden\" in item.lower() for item in x)\n",
    "# )\n",
    "\n",
    "# print(f\"Total garden mentions in garden data: {sum(garden_mentions_garden)}\")\n",
    "# print(f\"Total communal garden mentions in no garden data: {sum(communal_garden_mentions_no_garden)}\")\n",
    "# print(f\"Total garden mentions in no garden data: {sum(garden_mentions_no_garden)}\")\n",
    "# print(f\"Shape of garden data is {garden_data.shape}\")\n",
    "# print(f\"Shape of no garden data is {garden_no_garden_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"data/August 2023/\")\n",
    "files = [file for file in files if file != \".DS_Store\"]\n",
    "postcodes_set = set()\n",
    "\n",
    "for file in files:\n",
    "    postcode = file.split(\"_\")[-1].split(\".\")[0]\n",
    "    postcodes_set.add(postcode)\n",
    "postcode_list = list(postcodes_set)\n",
    "\n",
    "# Create an empty DataFrame to store the output\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Iterate over each postcode in the postcode_list\n",
    "for postcode in postcode_list:\n",
    "    # Read the no garden data and garden data for the current postcode\n",
    "    garden_no_garden_data = pd.read_parquet(f\"data/August 2023/house_data_no_garden_{postcode}.parquet\")\n",
    "    garden_data = pd.read_parquet(f\"data/August 2023/house_data_garden_{postcode}.parquet\")\n",
    "\n",
    "    # Merge the garden data and no garden data\n",
    "    garden_data_id = garden_data[\"id\"].tolist()\n",
    "    no_garden_data = garden_no_garden_data[~garden_no_garden_data[\"id\"].isin(garden_data_id)].copy()\n",
    "    no_garden_data.reset_index(drop=True, inplace=True)\n",
    "    no_garden_data[\"garden\"] = 0\n",
    "    garden_data[\"garden\"] = 1\n",
    "\n",
    "    merged_data = pd.concat([no_garden_data, garden_data])\n",
    "    merged_data.drop_duplicates(subset=[\"id\", \"description\", \"address\"], keep=\"last\", inplace=True)\n",
    "    \n",
    "    # Append the current iteration of all_data to the output_data DataFrame\n",
    "    all_data = pd.concat([merged_data, all_data])\n",
    "\n",
    "# Reset the index of the output_data DataFrame\n",
    "all_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn numeric columns into numeric types\n",
    "all_data['price'] = all_data['price'].str.replace('£', '').str.replace(',', '').astype(int)\n",
    "# Fill missing values with a default value (0 in this case)\n",
    "all_data['bathrooms'] = all_data['bathrooms'].fillna('0')\n",
    "all_data['bathrooms'] = all_data['bathrooms'].astype(\"int\")\n",
    "# Fill missing values with a default value (0 in this case)\n",
    "all_data['bedrooms'] = all_data['bedrooms'].fillna('0')\n",
    "all_data['bedrooms'] = all_data['bedrooms'].astype(\"int\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, extract the post code from the address    \n",
    "all_data[\"postcode\"] = all_data[\"address\"].apply(lambda x: x.split(\",\")[-1].replace(\" \", \"\"))\n",
    "\n",
    "# If the postcode isn't contained in the address or it uses a different forma than Nx\n",
    "# or NWx, then use geocoder to extract the postcode\n",
    "mask_postcode = all_data[\"postcode\"].str.len() > 4\n",
    "# Create a temporary dataframe to extract the postcode of the addresses in the mask\n",
    "no_postcode_data = all_data[mask_postcode].copy()\n",
    "no_postcode_data[\"road\"] = no_postcode_data[\"address\"].apply(lambda x: x.split(\",\")[0])\n",
    "no_postcode_data[\"postcode\"] = no_postcode_data[\"road\"].apply(find_postcode)\n",
    "# Copy the new postcode for the elements in the mask to the original dataframe\n",
    "all_data.loc[mask_postcode, \"postcode\"] = no_postcode_data[\"postcode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming no_postcode_data is your DataFrame\n",
    "# dask_dataframe = dd.from_pandas(no_postcode_data, npartitions=8)  # Adjust the number of partitions as needed\n",
    "\n",
    "# # Apply the find_postcode function using Dask's map_partitions\n",
    "# dask_dataframe[\"postcode\"] = dask_dataframe.map_partitions(lambda df: df[\"road\"].apply(find_postcode), meta=(\"postcode\", \"object\"))\n",
    "\n",
    "# # Compute the Dask DataFrame to get the final result\n",
    "# result_df = dask_dataframe.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data scraped from rightmove is in the format xxx sq. ft (xxx sq. m). We need to \n",
    "# extract the number before \"sq. ft\" using re\n",
    "mask_size = ~all_data[\"size\"].isna()\n",
    "mask_no_size = all_data[\"size\"].isna()\n",
    "# Create a copy of the data with missing size information\n",
    "size_data = all_data[mask_size].copy()\n",
    "# Extract the size from the floorplan for the houses with missing size information\n",
    "size_data[\"size\"] = size_data[\"size\"].apply(extract_area_from_dataframe)\n",
    "all_data.loc[mask_size, \"size\"] = size_data[\"size\"]\n",
    "# In the size information wasn't available in rightmove, we need to extract the \n",
    "# text from the floorplan and then extract the size\n",
    "# Create a copy of the data with missing size information\n",
    "# no_size_data = all_data[mask_no_size].copy()\n",
    "# Extract the size from the floorplan for the houses with missing size information\n",
    "# no_size_data[\"size\"] = no_size_data[\"id\"].apply(extract_area_from_floorplan)\n",
    "# Assuming no_postcode_data is your DataFrame\n",
    "dask_dataframe = dd.from_pandas(all_data[mask_no_size], npartitions=8)  # Adjust the number of partitions as needed\n",
    "\n",
    "# Apply the find_postcode function using Dask's map_partitions\n",
    "dask_dataframe[\"size\"] = dask_dataframe.map_partitions(lambda df: df[\"id\"].apply(extract_area_from_floorplan), meta=(\"id\", \"object\"))\n",
    "\n",
    "# Compute the Dask DataFrame to get the final result\n",
    "no_size_data = dask_dataframe.compute()\n",
    "# Update the size information in the original dataframe\n",
    "all_data.loc[mask_no_size, \"size\"] = no_size_data[\"size\"]\n",
    "all_data[\"size\"] = all_data[\"size\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the type of outdoor space (if any) and the floor level from the floorplan\n",
    "col_names = [\"outdoor_type\", \"floor\"]\n",
    "\n",
    "# Create a Dask delayed computation for each image_id\n",
    "delayed_results = [delayed(extract_other_data_from_floorplan)(image_id) for image_id in all_data[\"id\"]]\n",
    "\n",
    "# Compute the results using Dask multiprocessing\n",
    "with dask.config.set(scheduler=\"processes\"):\n",
    "    results = dask.compute(*delayed_results)\n",
    "\n",
    "# Update the DataFrame with computed results\n",
    "outdoor_space_values = [result[0] for result in results]\n",
    "floor_values = [result[1] for result in results]\n",
    "\n",
    "all_data[col_names[0]] = outdoor_space_values\n",
    "all_data[col_names[1]] = floor_values\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data[\"size_sqm\"] = all_data[\"size\"] * 0.092903\n",
    "all_data[\"price_sqm\"] = all_data[\"price\"] / (all_data[\"size\"] * 0.092903)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each postcode in the dataset\n",
    "postcode_counts = all_data[\"postcode\"].value_counts()\n",
    "# Filter out postcodes that appear less than 5 times\n",
    "postcode_counts_filtered = postcode_counts[postcode_counts >= 5]\n",
    "# Get a list of the filtered postcodes\n",
    "filtered_postcodes = postcode_counts_filtered.index.tolist()\n",
    "# Filter the data based on the filtered postcodes\n",
    "filtered_data = all_data[all_data[\"postcode\"].isin(filtered_postcodes)]\n",
    "# Define the columns to be used for analysis\n",
    "cols_analysis = [\"price\", \"price_sqm\"]\n",
    "# Group the filtered data by postcode and calculate the mean and median of the selected columns\n",
    "analysis_results = filtered_data.groupby(\"postcode\")[cols_analysis].aggregate([\"mean\", \"median\"]).round(1)\n",
    "# Print the analysis results\n",
    "analysis_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data[filtered_data[\"floor\"].isna()][[\"id\", \"size\", \"floor\"]].sample(15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_outliers = filtered_data[(filtered_data[\"size\"] < 275)]\n",
    "price_outliers[[\"id\",\"size\", \"floor\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = \"138272951\"\n",
    "print(extract_other_data_from_floorplan(image_id))\n",
    "command = f\"open media/floorplans/{image_id}_floorplan.png\"\n",
    "! {command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"garden\"] == 1 & ~all_data[\"garden_floorplan\"].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_garden = (all_data[\"garden\"] == 1) & (all_data[\"garden_floorplan\"].isna())\n",
    "all_data[mask_garden][[\"id\", \"garden\", \"garden_floorplan\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
